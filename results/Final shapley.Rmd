---
title: "Final Shapley Plots"
author: "Anna Wiewer"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load data and libraries
```{r}

# Load libraries
library(readr)
library(writexl)
library(psych)
library(nortest)
library(ggplot2)
library(Hmisc)
library(corrplot)
library(rstatix)
library(dplyr)
library(dlookr)
library(reshape2)
library(lightgbm)
library(caret)
library(pROC)
library(vip)
library(ggplot2)
library(DALEX)


#read data file
dataset <- read.csv("/Users/annawiewer/Desktop/Analytics Edge/Group project/Data/dataset (3).csv")

# Convert 'target' variable into a factor
dataset$Target <- factor(dataset$Target)
str(dataset)

#Redefine values for target variable
dataset <- dataset %>%
  mutate(Target = case_when(
    Target == 'Dropout' ~ 0,
    Target == 'Enrolled' ~ 2,
    Target == 'Graduate' ~ 1
  ))


#Note: imbalance in data set: Graduate (2209), Dropout (1421), Enrolled (794)

#Dataset with only enrolled students:
enrolled_data <- dataset[dataset$Target == 2, ]


# Dataset with drop and grad:
dropout_graduate_data <- dataset[dataset$Target %in% c(0, 1), ]

```


# Light XGBoost:
## Stage 1: At enrollment

```{r}

excluded_features<- c("Target", "Tuition.fees.up.to.date","Curricular.units.1st.sem..credited.",       "Curricular.units.1st.sem..evaluations.","Curricular.units.1st.sem..approved.",           "Curricular.units.1st.sem..grade.","Curricular.units.1st.sem..without.evaluations.", "Curricular.units.2nd.sem..credited.","Curricular.units.2nd.sem..enrolled.", "Curricular.units.2nd.sem..evaluations.","Curricular.units.2nd.sem..approved.", "Curricular.units.2nd.sem..grade.", "Curricular.units.2nd.sem..without.evaluations.","Curricular.units.1st.sem..enrolled.")


# Assign target and features
target <- dropout_graduate_data$Target
features <- dropout_graduate_data[, !(names(dropout_graduate_data) %in% excluded_features)]


# Split data into training and testing sets
set.seed(123)  # Setting seed for reproducibility
indices <- sample(1:nrow(features), size = 0.8 * nrow(features))
train_features <- features[indices, ]
train_target <- target[indices]
test_features <- features[-indices, ]
test_target <- target[-indices]

y_var <-  train_target
dataX <- as.matrix(train_features)

str(dataX)


# Convert to LightGBM dataset
dtrain <- lgb.Dataset(data = as.matrix(dataX), label = train_target)

# Define parameters
params <- list(
  objective = "binary",   # Use "binary" for binary classification
  metric = "binary_logloss",  # Binary log loss for binary classification
  num_leaves = 31,
  learning_rate = 0.05
)
params$num_leaves <- 15  # Optionally adjust based on data

# Train the model
model <- lgb.train(
  params = params,
  data = dtrain,
  nrounds = 100
)

# Prepare test data as a matrix
test_matrix <- as.matrix(test_features)

#Shapley values
shap_values <- shap.values(xgb_model = model, X_train = dataX)

shap_values$mean_shap_score

shap_values_drop <- shap_values$shap_score

# shap.prep() returns the long-format SHAP data from either model or
shap_long_drop <- shap.prep(xgb_model = model, X_train = dataX)

# is the same as: using given shap_contrib
shap_long_drop <- shap.prep(shap_contrib = shap_values_drop, X_train = dataX)

# **SHAP summary plot**
shap.plot.summary(shap_long_drop)

```

## Stage2: During 1st semester
```{r}

excluded_features<- c("Target", "Tuition.fees.up.to.date","Curricular.units.1st.sem..credited.",       "Curricular.units.1st.sem..evaluations.","Curricular.units.1st.sem..approved.",           "Curricular.units.1st.sem..grade.","Curricular.units.1st.sem..without.evaluations.", "Curricular.units.2nd.sem..credited.","Curricular.units.2nd.sem..enrolled.", "Curricular.units.2nd.sem..evaluations.","Curricular.units.2nd.sem..approved.", "Curricular.units.2nd.sem..grade.", "Curricular.units.2nd.sem..without.evaluations.")


# Assign target and features
target <- dropout_graduate_data$Target
features <- dropout_graduate_data[, !(names(dropout_graduate_data) %in% excluded_features)]


# Split data into training and testing sets
set.seed(123)  # Setting seed for reproducibility
indices <- sample(1:nrow(features), size = 0.8 * nrow(features))
train_features <- features[indices, ]
train_target <- target[indices]
test_features <- features[-indices, ]
test_target <- target[-indices]

y_var <-  train_target
dataX <- as.matrix(train_features)

str(dataX)


# Convert to LightGBM dataset
dtrain <- lgb.Dataset(data = as.matrix(dataX), label = train_target)

# Define parameters
params <- list(
  objective = "binary",   # Use "binary" for binary classification
  metric = "binary_logloss",  # Binary log loss for binary classification
  num_leaves = 31,
  learning_rate = 0.05
)
params$num_leaves <- 15  # Optionally adjust based on data

# Train the model
model <- lgb.train(
  params = params,
  data = dtrain,
  nrounds = 100
)

# Prepare test data as a matrix
test_matrix <- as.matrix(test_features)

#Shapley values
shap_values <- shap.values(xgb_model = model, X_train = dataX)

shap_values$mean_shap_score

shap_values_drop <- shap_values$shap_score

# shap.prep() returns the long-format SHAP data from either model or
shap_long_drop <- shap.prep(xgb_model = model, X_train = dataX)

# is the same as: using given shap_contrib
shap_long_drop <- shap.prep(shap_contrib = shap_values_drop, X_train = dataX)

# **SHAP summary plot**
shap.plot.summary(shap_long_drop)

```

